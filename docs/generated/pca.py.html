<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <title>pca.py</title>
  </head>
  <body>
    <h1>pca.py</h1>
<h2>Overview</h2>
<pre>

  pca.py performs principal component analysis on the first 2
  dimensions of its input file, looping over any other dimensions.


  pca.py [-v][-d] [-n nComponents] --eigenvectors evecDS
    [--eigenvalues evalDS] [--leftvectors leftvecDS] [--methodthresh nThresh]
    inputDS

   where:
    -v specifies verbose output
    -d specifies debugging output
    -n nComponents requests the given number of eigenvectors.  The
       default is all the eigenvectors.
    --eigenvectors evecDS specifies the (right) eigenvector output
       file.  This option is required.
    --eigenvalues evalDS specifies the eigenvalue output file.  If
       this option is omitted, eigenvalues are not produced.
    --leftvectors leftvecDS specifies the left eigenvector output file.
    --methodthresh nThresh specifies a matrix size threshold to change
       between algorithms.  See 'Details' below.  The default is 256.

  or

  pca.py -help [topic]

</pre>
<h2>Example</h2>
<pre>

  Consider a test dataset, named 'test', with dimensions "stw" and
  extents 8:28:17.  The command:

   pca.py -n 6 --eigenvectors evecs --eigenvalues evals --leftvectors lvecs test

  will produce the output datasets 'evecs', 'evals', and 'lvecs'.
  They will have the following dimensions:  

   evecs has dimensions taw, extents 28:6:17

   evals has dimensions aw, extents 6:17

   lvecs has dimensions saw, extents 8:6:17

</pre>
<h2>Details</h2>
<pre>

  The dimension used for the components ('a' in the Example above) is
  chosen to be distinct from any other dimension in the input matrix.
  Other than that, it could turn out to be anything; no promise is
  made that it will be 'a' in the Example above or that it won't
  change in future releases.

  If both of the first two dimensions of the input matrix have extents
  less than nThresh, the result is computed directly via singular
  value decomposition:

           T
    X = GLD

  where G is the matrix of left eigenvectors, L is a diagonal matrix of
  eigenvalues, and D (transposed in this equation) is the matrix of
  eigenvectors.

  If one or both dimensions has an extent above nThresh, and if the
  first extent is less than the second extent, the PCA is done via
  the covariance of X:

                   T
     compute M = XX   
                                  2
     find G and L such that MG = L M by eigenvector decomposition

              T   T
     compute d = G X

                  -1
     compute D = L  d

  If one or both dimensions has an extent above nThresh, and if the
  first extent is greater than or equal to the second extent, the PCA 
  is done as follows

                  T
     compute Q = X X   
                                  2
     find D and L such that QD = L Q by eigenvector decomposition

     compute g = XD

              T   -1 T
     compute G = L  g

  Remember that there is a sign ambiguity in the solutions, and
  different methods will produce results of different signs!


</pre>
    <hr>
    (automatically generated by pca.py version of Mon Jul 15 00:18:47 2019)
  </body>
</html>
